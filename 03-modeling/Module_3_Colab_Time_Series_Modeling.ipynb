{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhil-vijaykumar/StockMarketAnalytics/blob/main/03-modeling/Module_3_Colab_Time_Series_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1wruXmPvYWB",
        "outputId": "9e705e2f-a58d-45bc-f3f9-8bc48c7c3a8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.40)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.25.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.2.2)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.4)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.5)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vPfvfETy1Z0",
        "outputId": "a7e2a705-59a1-42af-ac34-4a4937313851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gdown 5.1.0\n",
            "Uninstalling gdown-5.1.0:\n",
            "  Successfully uninstalled gdown-5.1.0\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "Successfully installed gdown-5.2.0\n",
            "gdown 5.2.0 at /usr/local/lib/python3.10/dist-packages\n"
          ]
        }
      ],
      "source": [
        "# read files shared via google-drive-link\n",
        "# https://stackoverflow.com/questions/62759748/downloading-data-from-a-shared-google-drive-link-in-google-colab\n",
        "\n",
        "!pip uninstall gdown -y && pip install gdown\n",
        "!gdown -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ge4C2c2_w7Ac"
      },
      "outputs": [],
      "source": [
        "# IMPORTS\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Fin Data Sources\n",
        "import yfinance as yf\n",
        "import pandas_datareader as pdr\n",
        "\n",
        "#Data viz\n",
        "import plotly.graph_objs as go\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "import time\n",
        "from datetime import date\n",
        "\n",
        "# for graphs\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX7x0Ywww_fD"
      },
      "source": [
        "# 0) Dataset for Modeling: Final Preparations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddC_AcGUat5w"
      },
      "source": [
        "## 0.1) Importing data from Drive & defining variable sets\n",
        "* automated version need to have a daily updated file/database entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-s1660YysQd",
        "outputId": "f9def482-2604-40d3-e808-a05f7a0495f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1kNWWPi49td0EZhmi6LzNCa2ssC5IUxHP\n",
            "From (redirected): https://drive.google.com/uc?id=1kNWWPi49td0EZhmi6LzNCa2ssC5IUxHP&confirm=t&uuid=25e171eb-c0c7-497b-b801-326f0485a1ec\n",
            "To: /content/stocks_df_combined_2024_05_07.parquet.brotli\n",
            "100% 119M/119M [00:04<00:00, 26.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "# https://stackoverflow.com/questions/62759748/downloading-data-from-a-shared-google-drive-link-in-google-colab\n",
        "# truncated data from Module 2: https://drive.google.com/file/d/1m3Qisfs2XfWk6Sw_Uk5kHLWqwQ0q8SKb/view?usp=sharing\n",
        "!gdown https://drive.google.com/file/d/1kNWWPi49td0EZhmi6LzNCa2ssC5IUxHP/view?usp=sharing --fuzzy -O /content/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AsPVf4XT1JAZ"
      },
      "outputs": [],
      "source": [
        "# truncated\n",
        "# df = pd.read_parquet(\"/content/stocks_df_combined_trunc_2014_2023.parquet.brotli\", )\n",
        "\n",
        "# full dataset for 33 stocks\n",
        "df_full = pd.read_parquet(\"/content/stocks_df_combined_2024_05_07.parquet.brotli\", )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fiZOGqG1puH",
        "outputId": "5b36bb29-49c0-4ee3-f89c-770786df0b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 221142 entries, 0 to 5426\n",
            "Columns: 202 entries, Open to growth_btc_usd_365d\n",
            "dtypes: datetime64[ns](3), float64(128), int32(64), int64(5), object(2)\n",
            "memory usage: 288.5+ MB\n"
          ]
        }
      ],
      "source": [
        "df_full.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzFRVbklIW4q",
        "outputId": "d8ef9f0e-b513-48ff-9390-72fdfd1c1d85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Adj Close_x', 'Volume', 'Ticker',\n",
              "       'Year', 'Month', 'Weekday',\n",
              "       ...\n",
              "       'growth_brent_oil_7d', 'growth_brent_oil_30d', 'growth_brent_oil_90d',\n",
              "       'growth_brent_oil_365d', 'growth_btc_usd_1d', 'growth_btc_usd_3d',\n",
              "       'growth_btc_usd_7d', 'growth_btc_usd_30d', 'growth_btc_usd_90d',\n",
              "       'growth_btc_usd_365d'],\n",
              "      dtype='object', length=202)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_full.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfDKpGwtIawQ",
        "outputId": "b8161013-4037-45e2-ac57-7bb71d7be5dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['growth_1d',\n",
              " 'growth_3d',\n",
              " 'growth_7d',\n",
              " 'growth_30d',\n",
              " 'growth_90d',\n",
              " 'growth_365d',\n",
              " 'growth_dax_1d',\n",
              " 'growth_dax_3d',\n",
              " 'growth_dax_7d',\n",
              " 'growth_dax_30d',\n",
              " 'growth_dax_90d',\n",
              " 'growth_dax_365d',\n",
              " 'growth_snp500_1d',\n",
              " 'growth_snp500_3d',\n",
              " 'growth_snp500_7d',\n",
              " 'growth_snp500_30d',\n",
              " 'growth_snp500_90d',\n",
              " 'growth_snp500_365d',\n",
              " 'growth_dji_1d',\n",
              " 'growth_dji_3d',\n",
              " 'growth_dji_7d',\n",
              " 'growth_dji_30d',\n",
              " 'growth_dji_90d',\n",
              " 'growth_dji_365d',\n",
              " 'growth_epi_1d',\n",
              " 'growth_epi_3d',\n",
              " 'growth_epi_7d',\n",
              " 'growth_epi_30d',\n",
              " 'growth_epi_90d',\n",
              " 'growth_epi_365d',\n",
              " 'growth_gold_1d',\n",
              " 'growth_gold_3d',\n",
              " 'growth_gold_7d',\n",
              " 'growth_gold_30d',\n",
              " 'growth_gold_90d',\n",
              " 'growth_gold_365d',\n",
              " 'growth_wti_oil_1d',\n",
              " 'growth_wti_oil_3d',\n",
              " 'growth_wti_oil_7d',\n",
              " 'growth_wti_oil_30d',\n",
              " 'growth_wti_oil_90d',\n",
              " 'growth_wti_oil_365d',\n",
              " 'growth_brent_oil_1d',\n",
              " 'growth_brent_oil_3d',\n",
              " 'growth_brent_oil_7d',\n",
              " 'growth_brent_oil_30d',\n",
              " 'growth_brent_oil_90d',\n",
              " 'growth_brent_oil_365d',\n",
              " 'growth_btc_usd_1d',\n",
              " 'growth_btc_usd_3d',\n",
              " 'growth_btc_usd_7d',\n",
              " 'growth_btc_usd_30d',\n",
              " 'growth_btc_usd_90d',\n",
              " 'growth_btc_usd_365d']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# growth indicators (but not future growth)\n",
        "GROWTH = [g for g in df_full.keys() if (g.find('growth_')==0)&(g.find('future')<0)]\n",
        "GROWTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "O28ePT2AI892"
      },
      "outputs": [],
      "source": [
        "# leaving only Volume ==> generate ln(Volume)\n",
        "OHLCV = ['Open','High','Low','Close','Adj Close_x','Volume']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FVcJZDyGbH2N"
      },
      "outputs": [],
      "source": [
        "CATEGORICAL = ['Month', 'Weekday', 'Ticker', 'ticker_type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7kZrwZiIpCN",
        "outputId": "45e8a6b0-dbd3-455f-fa14-122918b51a73"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['growth_future_5d', 'is_positive_growth_5d_future']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "TO_PREDICT = [g for g in df_full.keys() if (g.find('future')>=0)]\n",
        "TO_PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tZF13UbOXGF",
        "outputId": "02ae6b60-5bca-4237-be06-b97e6efad1f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Year',\n",
              " 'Date',\n",
              " 'index_x',\n",
              " 'index_y',\n",
              " 'index',\n",
              " 'Quarter',\n",
              " 'Adj Close_y',\n",
              " 'Month',\n",
              " 'Weekday',\n",
              " 'Ticker',\n",
              " 'ticker_type',\n",
              " 'Open',\n",
              " 'High',\n",
              " 'Low',\n",
              " 'Close',\n",
              " 'Adj Close_x',\n",
              " 'Volume']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "TO_DROP = ['Year','Date','index_x', 'index_y', 'index', 'Quarter','Adj Close_y'] + CATEGORICAL + OHLCV\n",
        "TO_DROP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VgBFjAADfXSp"
      },
      "outputs": [],
      "source": [
        "# let's define on more custom numerical features\n",
        "df_full['ln_volume'] = df_full.Volume.apply(lambda x: np.log(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lukhBLIcfW8g"
      },
      "outputs": [],
      "source": [
        "# manually defined features\n",
        "CUSTOM_NUMERICAL = ['SMA10', 'SMA20', 'growing_moving_average', 'high_minus_low_relative','volatility', 'ln_volume']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IpRKmVtaf6is"
      },
      "outputs": [],
      "source": [
        "# All Supported Ta-lib indicators: https://github.com/TA-Lib/ta-lib-python/blob/master/docs/funcs.md\n",
        "\n",
        "TECHNICAL_INDICATORS = ['adx', 'adxr', 'apo', 'aroon_1','aroon_2', 'aroonosc',\n",
        " 'bop', 'cci', 'cmo','dx', 'macd', 'macdsignal', 'macdhist', 'macd_ext',\n",
        " 'macdsignal_ext', 'macdhist_ext', 'macd_fix', 'macdsignal_fix',\n",
        " 'macdhist_fix', 'mfi', 'minus_di', 'mom', 'plus_di', 'dm', 'ppo',\n",
        " 'roc', 'rocp', 'rocr', 'rocr100', 'rsi', 'slowk', 'slowd', 'fastk',\n",
        " 'fastd', 'fastk_rsi', 'fastd_rsi', 'trix', 'ultosc', 'willr',\n",
        " 'ad', 'adosc', 'obv', 'atr', 'natr', 'ht_dcperiod', 'ht_dcphase',\n",
        " 'ht_phasor_inphase', 'ht_phasor_quadrature', 'ht_sine_sine', 'ht_sine_leadsine',\n",
        " 'ht_trendmod', 'avgprice', 'medprice', 'typprice', 'wclprice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncPdBnx13ilm",
        "outputId": "4100c456-2094-435b-f9eb-8f39ef6e475b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Technical patterns count = 61, examples = ['cdl2crows', 'cdl3blackrows', 'cdl3inside', 'cdl3linestrike', 'cdl3outside']\n"
          ]
        }
      ],
      "source": [
        "TECHNICAL_PATTERNS = [g for g in df_full.keys() if g.find('cdl')>=0]\n",
        "print(f'Technical patterns count = {len(TECHNICAL_PATTERNS)}, examples = {TECHNICAL_PATTERNS[0:5]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SUa1pIvB4o5w"
      },
      "outputs": [],
      "source": [
        "MACRO = ['gdppot_us_yoy', 'gdppot_us_qoq', 'cpi_core_yoy', 'cpi_core_mom', 'FEDFUNDS',\n",
        " 'DGS1', 'DGS5', 'DGS10']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nakB0XZA1uFq"
      },
      "outputs": [],
      "source": [
        "NUMERICAL = GROWTH + TECHNICAL_INDICATORS + TECHNICAL_PATTERNS + CUSTOM_NUMERICAL + MACRO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri9F9mIwIuVa",
        "outputId": "9d25ca82-2c7f-4564-88ed-014c0e3c460b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['growth_future_5d', 'is_positive_growth_5d_future']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# CHECK: NO OTHER INDICATORS LEFT\n",
        "OTHER = [k for k in df_full.keys() if k not in OHLCV + CATEGORICAL + NUMERICAL + TO_DROP]\n",
        "OTHER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zv_OOrK1ulV",
        "outputId": "674ea6ea-ed56-418c-822d-10641c79e749"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df_full.Ticker.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7bPKU1Z612OK",
        "outputId": "7768a423-85aa-4aa1-d818-26b25445fc23"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     min        max  count\n",
              "Ticker                                    \n",
              "AAPL          1980-12-12 2024-05-07  10941\n",
              "ACN           2001-07-19 2024-05-07   5736\n",
              "AMZN          1997-05-15 2024-05-07   6789\n",
              "ASML          1995-03-15 2024-05-07   7338\n",
              "AVGO          2009-08-06 2024-05-07   3713\n",
              "BHARTIARTL.NS 2002-07-01 2024-05-07   5424\n",
              "BRK-B         1996-05-09 2024-05-07   7046\n",
              "CDI.PA        1992-01-27 2024-05-07   8328\n",
              "GOOG          2004-08-19 2024-05-07   4963\n",
              "HDB           2001-07-20 2024-05-07   5735\n",
              "HINDUNILVR.NS 1996-01-01 2024-05-07   7122\n",
              "IBN           2000-03-28 2024-05-07   6066\n",
              "IDEXY         2010-01-20 2024-05-07   3599\n",
              "INFY          1999-03-11 2024-05-07   6331\n",
              "ITC.NS        1996-01-01 2024-05-07   7119\n",
              "JPM           1980-03-17 2024-05-07  11129\n",
              "LICI.NS       2022-05-17 2024-05-07    487\n",
              "LLY           1972-06-01 2024-05-07  13095\n",
              "LT.NS         2002-07-01 2024-05-07   5427\n",
              "MC.PA         2000-01-03 2024-05-07   6258\n",
              "META          2012-05-18 2024-05-07   3011\n",
              "MSFT          1986-03-13 2024-05-07   9615\n",
              "NVDA          1999-01-22 2024-05-07   6364\n",
              "NVO           1981-04-30 2024-05-07  10846\n",
              "OR.PA         2000-01-03 2024-05-07   6258\n",
              "RELIANCE.NS   1996-01-01 2024-05-07   7119\n",
              "RMS.PA        2000-01-03 2024-05-07   6258\n",
              "SAP           1995-09-18 2024-05-07   7209\n",
              "SBIN.NS       1996-01-01 2024-05-07   7120\n",
              "SIE.DE        1996-11-08 2024-05-07   7046\n",
              "TCS.NS        2002-08-12 2024-05-07   5395\n",
              "TTE           1991-10-25 2024-05-07   8193\n",
              "V             2008-03-19 2024-05-07   4062"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69ff9752-32e4-4635-92d3-3f59e68b60cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ticker</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AAPL</th>\n",
              "      <td>1980-12-12</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>10941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ACN</th>\n",
              "      <td>2001-07-19</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>5736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMZN</th>\n",
              "      <td>1997-05-15</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>6789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ASML</th>\n",
              "      <td>1995-03-15</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>7338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AVGO</th>\n",
              "      <td>2009-08-06</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>3713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BHARTIARTL.NS</th>\n",
              "      <td>2002-07-01</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>5424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BRK-B</th>\n",
              "      <td>1996-05-09</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>7046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CDI.PA</th>\n",
              "      <td>1992-01-27</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>8328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOOG</th>\n",
              "      <td>2004-08-19</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>4963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HDB</th>\n",
              "      <td>2001-07-20</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>5735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HINDUNILVR.NS</th>\n",
              "      <td>1996-01-01</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>7122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IBN</th>\n",
              "      <td>2000-03-28</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>6066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IDEXY</th>\n",
              "      <td>2010-01-20</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>3599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INFY</th>\n",
              "      <td>1999-03-11</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>6331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ITC.NS</th>\n",
              "      <td>1996-01-01</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>7119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JPM</th>\n",
              "      <td>1980-03-17</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>11129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LICI.NS</th>\n",
              "      <td>2022-05-17</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LLY</th>\n",
              "      <td>1972-06-01</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>13095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LT.NS</th>\n",
              "      <td>2002-07-01</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>5427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MC.PA</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>6258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>META</th>\n",
              "      <td>2012-05-18</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>3011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MSFT</th>\n",
              "      <td>1986-03-13</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>9615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NVDA</th>\n",
              "      <td>1999-01-22</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>6364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NVO</th>\n",
              "      <td>1981-04-30</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>10846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OR.PA</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>6258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RELIANCE.NS</th>\n",
              "      <td>1996-01-01</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>7119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMS.PA</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>6258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SAP</th>\n",
              "      <td>1995-09-18</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>7209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SBIN.NS</th>\n",
              "      <td>1996-01-01</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>7120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SIE.DE</th>\n",
              "      <td>1996-11-08</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>7046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TCS.NS</th>\n",
              "      <td>2002-08-12</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>5395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TTE</th>\n",
              "      <td>1991-10-25</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>8193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>V</th>\n",
              "      <td>2008-03-19</td>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>4062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69ff9752-32e4-4635-92d3-3f59e68b60cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-69ff9752-32e4-4635-92d3-3f59e68b60cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-69ff9752-32e4-4635-92d3-3f59e68b60cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ca3ad389-8716-414b-ad99-491b76d94f36\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca3ad389-8716-414b-ad99-491b76d94f36')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ca3ad389-8716-414b-ad99-491b76d94f36 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_full\",\n  \"rows\": 33,\n  \"fields\": [\n    {\n      \"column\": \"Ticker\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"TTE\",\n          \"JPM\",\n          \"RMS.PA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1972-06-01 00:00:00\",\n        \"max\": \"2022-05-17 00:00:00\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"2004-08-19 00:00:00\",\n          \"1999-03-11 00:00:00\",\n          \"2001-07-20 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-05-07 00:00:00\",\n        \"max\": \"2024-05-07 00:00:00\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2024-05-07 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2496,\n        \"min\": 487,\n        \"max\": 13095,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          8193\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# tickers, min-max date, count of daily observations\n",
        "df_full.groupby(['Ticker'])['Date'].agg(['min','max','count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmIpnwsJLvtI",
        "outputId": "11062501-f129-4de1-afbe-521c144d9f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 182675 entries, 3490 to 5426\n",
            "Columns: 203 entries, Open to ln_volume\n",
            "dtypes: datetime64[ns](3), float64(129), int32(64), int64(5), object(2)\n",
            "memory usage: 239.7+ MB\n"
          ]
        }
      ],
      "source": [
        "# truncated df_full with 25 years of data (and defined growth variables)\n",
        "df = df_full[df_full.Date>='2000-01-01']\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1idq4ieQ_ac",
        "outputId": "a01a96dd-eca2-421b-bc37-03f7b298c1c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 182675 entries, 3490 to 5426\n",
            "Columns: 184 entries, growth_1d to DGS10\n",
            "dtypes: float64(121), int32(62), int64(1)\n",
            "memory usage: 214.6 MB\n"
          ]
        }
      ],
      "source": [
        "# let look at the features count and size:\n",
        "df[NUMERICAL].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK6TYOZIcBNU"
      },
      "source": [
        "## 0.2) [Code snippet 1] Generating dummies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjfA2dyIeCDn",
        "outputId": "e27e1e33-a42e-4b57-a8c6-8a13d4f749c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Month', 'Weekday', 'Ticker', 'ticker_type']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# what are the categorical features?\n",
        "CATEGORICAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pa-AoEDeLX4x"
      },
      "outputs": [],
      "source": [
        "# dummy variables are not generated from Date and numeric variables\n",
        "df.loc[:,'Month'] = df.Month.dt.strftime('%B')\n",
        "df.loc[:,'Weekday'] = df.Weekday.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tuAlw48XKjE5"
      },
      "outputs": [],
      "source": [
        "# Generate dummy variables (no need for bool, let's have int32 instead)\n",
        "dummy_variables = pd.get_dummies(df[CATEGORICAL], dtype='int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dovxcVkk-72S"
      },
      "outputs": [],
      "source": [
        "# TODO 1: define more categorical features, e.g. all combinations for <September+weekday>  (you'll see that September is actually an important dummy in one of the models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzzG2DfZKpFn",
        "outputId": "9409a70f-b7d7-439a-834b-1f0e1d0338b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 182675 entries, 3490 to 5426\n",
            "Data columns (total 55 columns):\n",
            " #   Column                Non-Null Count   Dtype\n",
            "---  ------                --------------   -----\n",
            " 0   Month_April           182675 non-null  int32\n",
            " 1   Month_August          182675 non-null  int32\n",
            " 2   Month_December        182675 non-null  int32\n",
            " 3   Month_February        182675 non-null  int32\n",
            " 4   Month_January         182675 non-null  int32\n",
            " 5   Month_July            182675 non-null  int32\n",
            " 6   Month_June            182675 non-null  int32\n",
            " 7   Month_March           182675 non-null  int32\n",
            " 8   Month_May             182675 non-null  int32\n",
            " 9   Month_November        182675 non-null  int32\n",
            " 10  Month_October         182675 non-null  int32\n",
            " 11  Month_September       182675 non-null  int32\n",
            " 12  Weekday_0             182675 non-null  int32\n",
            " 13  Weekday_1             182675 non-null  int32\n",
            " 14  Weekday_2             182675 non-null  int32\n",
            " 15  Weekday_3             182675 non-null  int32\n",
            " 16  Weekday_4             182675 non-null  int32\n",
            " 17  Weekday_5             182675 non-null  int32\n",
            " 18  Weekday_6             182675 non-null  int32\n",
            " 19  Ticker_AAPL           182675 non-null  int32\n",
            " 20  Ticker_ACN            182675 non-null  int32\n",
            " 21  Ticker_AMZN           182675 non-null  int32\n",
            " 22  Ticker_ASML           182675 non-null  int32\n",
            " 23  Ticker_AVGO           182675 non-null  int32\n",
            " 24  Ticker_BHARTIARTL.NS  182675 non-null  int32\n",
            " 25  Ticker_BRK-B          182675 non-null  int32\n",
            " 26  Ticker_CDI.PA         182675 non-null  int32\n",
            " 27  Ticker_GOOG           182675 non-null  int32\n",
            " 28  Ticker_HDB            182675 non-null  int32\n",
            " 29  Ticker_HINDUNILVR.NS  182675 non-null  int32\n",
            " 30  Ticker_IBN            182675 non-null  int32\n",
            " 31  Ticker_IDEXY          182675 non-null  int32\n",
            " 32  Ticker_INFY           182675 non-null  int32\n",
            " 33  Ticker_ITC.NS         182675 non-null  int32\n",
            " 34  Ticker_JPM            182675 non-null  int32\n",
            " 35  Ticker_LICI.NS        182675 non-null  int32\n",
            " 36  Ticker_LLY            182675 non-null  int32\n",
            " 37  Ticker_LT.NS          182675 non-null  int32\n",
            " 38  Ticker_MC.PA          182675 non-null  int32\n",
            " 39  Ticker_META           182675 non-null  int32\n",
            " 40  Ticker_MSFT           182675 non-null  int32\n",
            " 41  Ticker_NVDA           182675 non-null  int32\n",
            " 42  Ticker_NVO            182675 non-null  int32\n",
            " 43  Ticker_OR.PA          182675 non-null  int32\n",
            " 44  Ticker_RELIANCE.NS    182675 non-null  int32\n",
            " 45  Ticker_RMS.PA         182675 non-null  int32\n",
            " 46  Ticker_SAP            182675 non-null  int32\n",
            " 47  Ticker_SBIN.NS        182675 non-null  int32\n",
            " 48  Ticker_SIE.DE         182675 non-null  int32\n",
            " 49  Ticker_TCS.NS         182675 non-null  int32\n",
            " 50  Ticker_TTE            182675 non-null  int32\n",
            " 51  Ticker_V              182675 non-null  int32\n",
            " 52  ticker_type_EU        182675 non-null  int32\n",
            " 53  ticker_type_INDIA     182675 non-null  int32\n",
            " 54  ticker_type_US        182675 non-null  int32\n",
            "dtypes: int32(55)\n",
            "memory usage: 39.7 MB\n"
          ]
        }
      ],
      "source": [
        "dummy_variables.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sxLHnVE3RaaU"
      },
      "outputs": [],
      "source": [
        "# get dummies names in a list\n",
        "DUMMIES = dummy_variables.keys().to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "j0e65F71Kl15"
      },
      "outputs": [],
      "source": [
        "# Concatenate the dummy variables with the original DataFrame\n",
        "df_with_dummies = pd.concat([df, dummy_variables], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qim1MIwUWE9",
        "outputId": "e3d6f8ca-390f-4768-adc1-6bd2eb10f05b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 182675 entries, 3490 to 5426\n",
            "Columns: 239 entries, growth_1d to ticker_type_US\n",
            "dtypes: float64(121), int32(117), int64(1)\n",
            "memory usage: 253.0 MB\n"
          ]
        }
      ],
      "source": [
        "df_with_dummies[NUMERICAL+DUMMIES].info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZl0ilI_Vx-O"
      },
      "source": [
        "## 0.3) [Code Snippet 2] Correlation analysis\n",
        "* first approximation of \"important\" variables correlated with all variables we want to predict (TO_PREDICT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4EVjxDMWHEP",
        "outputId": "0f7d2955-e76e-47e6-cfdd-16a58aaef917"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['growth_future_5d', 'is_positive_growth_5d_future']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "TO_PREDICT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "no3MkU5AWCDF"
      },
      "outputs": [],
      "source": [
        "corr_is_positive_growth_5d_future = df_with_dummies[NUMERICAL+DUMMIES+TO_PREDICT].corr()['is_positive_growth_5d_future']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtcXzUDaWshV"
      },
      "outputs": [],
      "source": [
        "# create a dataframe for an easy way to sort\n",
        "corr_is_positive_growth_5d_future_df = pd.DataFrame(corr_is_positive_growth_5d_future)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9rCxGhGXavp"
      },
      "outputs": [],
      "source": [
        "corr_is_positive_growth_5d_future_df.sort_values(by='is_positive_growth_5d_future').head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXk1b0goXfsI"
      },
      "outputs": [],
      "source": [
        "corr_is_positive_growth_5d_future_df.sort_values(by='is_positive_growth_5d_future').tail(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWrEqmLSXml3"
      },
      "outputs": [],
      "source": [
        "corr_growth_future_5d = df_with_dummies[NUMERICAL+DUMMIES+TO_PREDICT].corr()['growth_future_5d']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OY06BtPwXzWc"
      },
      "outputs": [],
      "source": [
        "corr_growth_future_5d_df = pd.DataFrame(corr_growth_future_5d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I6hcmFcX1G8"
      },
      "outputs": [],
      "source": [
        "corr_growth_future_5d_df.sort_values(by='growth_future_5d').head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piFZJuu7X98b"
      },
      "outputs": [],
      "source": [
        "corr_growth_future_5d_df.sort_values(by='growth_future_5d').tail(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDcUuE1atTM8"
      },
      "source": [
        "## 0.4) [Code snippet 3] Temporal split of ~25 years of data (by date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loo6ktrtvKrn"
      },
      "outputs": [],
      "source": [
        "def temporal_split(df, min_date, max_date, train_prop=0.7, val_prop=0.15, test_prop=0.15):\n",
        "    \"\"\"\n",
        "    Splits a DataFrame into three buckets based on the temporal order of the 'Date' column.\n",
        "\n",
        "    Args:\n",
        "        df (DataFrame): The DataFrame to split.\n",
        "        min_date (str or Timestamp): Minimum date in the DataFrame.\n",
        "        max_date (str or Timestamp): Maximum date in the DataFrame.\n",
        "        train_prop (float): Proportion of data for training set (default: 0.6).\n",
        "        val_prop (float): Proportion of data for validation set (default: 0.2).\n",
        "        test_prop (float): Proportion of data for test set (default: 0.2).\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: The input DataFrame with a new column 'split' indicating the split for each row.\n",
        "    \"\"\"\n",
        "    # Define the date intervals\n",
        "    train_end = min_date + pd.Timedelta(days=(max_date - min_date).days * train_prop)\n",
        "    val_end = train_end + pd.Timedelta(days=(max_date - min_date).days * val_prop)\n",
        "\n",
        "    # Assign split labels based on date ranges\n",
        "    split_labels = []\n",
        "    for date in df['Date']:\n",
        "        if date <= train_end:\n",
        "            split_labels.append('train')\n",
        "        elif date <= val_end:\n",
        "            split_labels.append('validation')\n",
        "        else:\n",
        "            split_labels.append('test')\n",
        "\n",
        "    # Add 'split' column to the DataFrame\n",
        "    df['split'] = split_labels\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0gVQMUEyNIc"
      },
      "outputs": [],
      "source": [
        "min_date_df = df_with_dummies.Date.min()\n",
        "max_date_df = df_with_dummies.Date.max()\n",
        "\n",
        "df_with_dummies = temporal_split(df_with_dummies,\n",
        "                                 min_date = min_date_df,\n",
        "                                 max_date = max_date_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-aPYFprylhp"
      },
      "outputs": [],
      "source": [
        "df_with_dummies['split'].value_counts()/len(df_with_dummies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPoJV5bnUnKr"
      },
      "outputs": [],
      "source": [
        "# remove the \"segmentation\" problem (warning message on df performance after many joins and data transformations)\n",
        "new_df = df_with_dummies.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOIxiUAEyBOo"
      },
      "source": [
        "# 1) Modeling: \"rule of thumb\" or hand-predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUu-tssz2ucr"
      },
      "outputs": [],
      "source": [
        "# let's have a time-series or one ticker\n",
        "df_nvda = new_df[new_df.Ticker=='NVDA']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8zbc8Y5245l"
      },
      "outputs": [],
      "source": [
        "fig = px.line(df_nvda, x=\"Date\", y=\"Adj Close_x\", title='NVDA price')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPHyYum23OUz"
      },
      "outputs": [],
      "source": [
        "# TRAIN / VALIDATION/ TEST split\n",
        "\n",
        "# Calculate the lengths of each split -- this is not temporal split, but based on the number of observations --> \"classic\" split with no shuffle\n",
        "total_length = len(df_nvda)\n",
        "train_length = int(0.8 * total_length)\n",
        "val_length = int(0.1 * total_length)\n",
        "\n",
        "# Split the data\n",
        "train_data = df_nvda.iloc[:train_length]\n",
        "val_data = df_nvda.iloc[train_length:train_length+val_length]\n",
        "test_data = df_nvda.iloc[train_length+val_length:]\n",
        "\n",
        "# Plot the data\n",
        "fig = px.line(title='NVDA Adj.Close price daily for three time intervals Train/Validation/Test')\n",
        "fig.add_scatter(x=train_data['Date'], y=train_data['Adj Close_x'], mode='lines', name='Train', line=dict(color='blue'))\n",
        "fig.add_scatter(x=val_data['Date'], y=val_data['Adj Close_x'], mode='lines', name='Validation', line=dict(color='orange'))\n",
        "fig.add_scatter(x=test_data['Date'], y=test_data['Adj Close_x'], mode='lines', name='Test', line=dict(color='green'))\n",
        "\n",
        "# Update layout to center the title\n",
        "fig.update_layout(title=dict(x=0.5))\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-QZp5emfqG-"
      },
      "outputs": [],
      "source": [
        "# HIST ON NVDA DATA Train/Test/Validation\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Plot the data\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add histograms for each split\n",
        "fig.add_trace(go.Histogram(x=train_data['growth_future_5d'], name='Train', opacity=0.75))\n",
        "fig.add_trace(go.Histogram(x=val_data['growth_future_5d'], name='Validation', opacity=0.75))\n",
        "fig.add_trace(go.Histogram(x=test_data['growth_future_5d'], name='Test', opacity=0.75))\n",
        "\n",
        "fig.update_layout(barmode='overlay', title='Distribution of growth_future_5d for NVIDIA (NVDA) Growth by Train/Valid/Test sets')\n",
        "fig.update_traces(opacity=0.75)\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yfGUpbZO5bq"
      },
      "outputs": [],
      "source": [
        "# HIST ON ALL DATA Train/Test/Validation\n",
        "# comment: there are some outliers and hard co compare the distributions\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Plot the data\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add histograms for each split\n",
        "fig.add_trace(go.Histogram(x=df_with_dummies[df_with_dummies.split=='train']['growth_future_5d'], name='Train', opacity=0.75))\n",
        "fig.add_trace(go.Histogram(x=df_with_dummies[df_with_dummies.split=='validation']['growth_future_5d'], name='Validation', opacity=0.75))\n",
        "fig.add_trace(go.Histogram(x=df_with_dummies[df_with_dummies.split=='test']['growth_future_5d'], name='Test', opacity=0.75))\n",
        "\n",
        "fig.update_layout(barmode='overlay', title='Distribution of growth_future_5d for All tickers Growth by Train/Valid/Test sets')\n",
        "fig.update_traces(opacity=0.75)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVNA_D8SRaOu"
      },
      "outputs": [],
      "source": [
        "# Assuming df_with_dummies is your DataFrame containing the 'growth_future_5d' variable and 'split' column\n",
        "\n",
        "# Create the histogram\n",
        "fig = px.histogram(new_df,\n",
        "                   x=\"growth_future_5d\",\n",
        "                   color=\"split\",\n",
        "                   marginal=\"box\", # or violin, rug\n",
        "                   )\n",
        "                  #  hover_data=new_df.growth_future_5d)\n",
        "\n",
        "# Show the histogram\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8FJKGTxTeRF"
      },
      "outputs": [],
      "source": [
        "new_df.groupby(by='split')['growth_future_5d'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHJnY-hrgc5i"
      },
      "outputs": [],
      "source": [
        "# is_positive_growth_5d_future: ONLY NVDA stock\n",
        "\n",
        "# Count occurrences of 0 and 1 for each split\n",
        "train_counts = train_data['is_positive_growth_5d_future'].value_counts(normalize=True)*100\n",
        "val_counts = val_data['is_positive_growth_5d_future'].value_counts(normalize=True)*100\n",
        "test_counts = test_data['is_positive_growth_5d_future'].value_counts(normalize=True)*100\n",
        "\n",
        "# Plot the data\n",
        "fig = go.Figure()\n",
        "\n",
        "# # Add stacked bar charts for each split\n",
        "# fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[0], val_counts[0], test_counts[0]], name='0'))\n",
        "# fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[1], val_counts[1], test_counts[1]], name='1'))\n",
        "\n",
        "\n",
        "# Add stacked bar charts for each split\n",
        "fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[0], val_counts[0], test_counts[0]], name='0',\n",
        "                     text=[f'{count:.2f}%' for count in [train_counts[0], val_counts[0], test_counts[0]]], textposition='auto'))\n",
        "fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[1], val_counts[1], test_counts[1]], name='1',\n",
        "                     text=[f'{count:.2f}%' for count in [train_counts[1], val_counts[1], test_counts[1]]], textposition='auto'))\n",
        "\n",
        "\n",
        "fig.update_layout(barmode='stack', title='Distribution of is_positive_growth_5d_future by Train/Validation/Test for NVDA stock')\n",
        "fig.update_traces(opacity=0.75)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWb_JFZ-hkfR"
      },
      "outputs": [],
      "source": [
        "# ALL STOCKS: train/test/validation is more similar\n",
        "\n",
        "# Count occurrences of 0 and 1 for each split\n",
        "train_counts = df_with_dummies[df_with_dummies.split=='train']['is_positive_growth_5d_future'].value_counts(normalize=True)*100\n",
        "val_counts = df_with_dummies[df_with_dummies.split=='validation']['is_positive_growth_5d_future'].value_counts(normalize=True)*100\n",
        "test_counts = df_with_dummies[df_with_dummies.split=='test']['is_positive_growth_5d_future'].value_counts(normalize=True)*100\n",
        "\n",
        "# Plot the data\n",
        "fig = go.Figure()\n",
        "\n",
        "\n",
        "# Add stacked bar charts for each split\n",
        "fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[0], val_counts[0], test_counts[0]], name='0',\n",
        "                     text=[f'{count:.2f}%' for count in [train_counts[0], val_counts[0], test_counts[0]]], textposition='auto'))\n",
        "fig.add_trace(go.Bar(x=['Train', 'Validation', 'Test'], y=[train_counts[1], val_counts[1], test_counts[1]], name='1',\n",
        "                     text=[f'{count:.2f}%' for count in [train_counts[1], val_counts[1], test_counts[1]]], textposition='auto'))\n",
        "\n",
        "\n",
        "fig.update_layout(barmode='stack', title='Distribution of is_positive_growth_5d_future by Train/Validation/Test for ALL stocks')\n",
        "fig.update_traces(opacity=0.75)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcaqMnIMPssp"
      },
      "source": [
        "# 1) Modeling: \"rule of thumb\" or hand-predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF5tSoLNrpE_"
      },
      "source": [
        "## 1.1) Review all the inputs again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2qCynDQBMpV"
      },
      "outputs": [],
      "source": [
        "# remove the \"segmentation\" problem (warning message on df performance after many joins and data transformations)\n",
        "new_df = df_with_dummies.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZtHf2IDPf_8"
      },
      "outputs": [],
      "source": [
        "# Full dataframe (transformed and truncated to 25 years)\n",
        "new_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRAp67SPiyW4"
      },
      "outputs": [],
      "source": [
        "# check one record: it has abs. values, text, and numbers\n",
        "new_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zvzkXNgjF1O"
      },
      "outputs": [],
      "source": [
        "# time split on train/validation/test: FIXED dates of split, approx. 70%, 15%, 15% split\n",
        "new_df.groupby(['split'])['Date'].agg({'min','max','count'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQtiyAyIqfsZ"
      },
      "outputs": [],
      "source": [
        "# what we try to predict\n",
        "new_df[TO_PREDICT].head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8fQBotSi0CQ"
      },
      "outputs": [],
      "source": [
        "# to be used as features\n",
        "new_df[NUMERICAL+DUMMIES].head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N012tLusJNx"
      },
      "source": [
        "## 1.2) [Code Snippet 3] Manual \"hand rule\" predictions\n",
        "* CCI (binary, on technical indicator CCI)\n",
        "* growth_1d>0\n",
        "* growth_1d>0 & growth_snp500_1d>0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mx1uWgl9Az2"
      },
      "outputs": [],
      "source": [
        "# why does it work?\n",
        "# compare a vector (pandas.core.series.Series) with scalar 200 ==> element_wise comparison with the number\n",
        "new_df.cci>200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ujwk8Rpxi5jQ"
      },
      "outputs": [],
      "source": [
        "# generate manual predictions\n",
        "# Let's label all prediction features with prefix \"pred\"\n",
        "new_df['pred0_manual_cci'] = (new_df.cci>200).astype(int)\n",
        "new_df['pred1_manual_prev_g1'] = (new_df.growth_1d>1).astype(int)\n",
        "new_df['pred2_manual_prev_g1_and_snp'] = ((new_df['growth_1d'] > 1) & (new_df['growth_snp500_1d'] > 1)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPkWi2Mp-hJ_"
      },
      "outputs": [],
      "source": [
        "# TODO 2: find more \"hand rules\" - can get it from decision trees important factors, or randomly build on other most popular macro/tech indicators/ manual_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-p0SvKtxU0m"
      },
      "outputs": [],
      "source": [
        "new_df[['cci','growth_1d','growth_snp500_1d','pred0_manual_cci','pred1_manual_prev_g1','pred2_manual_prev_g1_and_snp','is_positive_growth_5d_future']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqYgFqGLA-Ar"
      },
      "outputs": [],
      "source": [
        "PREDICTIONS = [k for k in new_df.keys() if k.startswith('pred')]\n",
        "PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpnYWgiTBd48"
      },
      "outputs": [],
      "source": [
        "p = PREDICTIONS[0]\n",
        "part1 = p.split('_')[0] # first prefix before '_'\n",
        "print(f'Full column name: {p}, only first part: {part1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcy-ZKcEx315"
      },
      "outputs": [],
      "source": [
        "# One prediction: do we predict correctly?\n",
        "new_df['is_correct_prediction'] = (new_df.pred0_manual_cci == new_df.is_positive_growth_5d_future)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sCpxLbtEYOG"
      },
      "outputs": [],
      "source": [
        "new_df[['cci','pred0_manual_cci','is_positive_growth_5d_future','is_correct_prediction']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znAWepdQE4vg"
      },
      "outputs": [],
      "source": [
        "# check \"Precision\" : the percentage of \"correct\" predictions , WHEN we predict \"1\" (POSITIVE future growth)\n",
        "filter = (new_df.split=='test') & (new_df.pred0_manual_cci==1)\n",
        "new_df[filter].is_correct_prediction.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z4mWTnfFDlc"
      },
      "outputs": [],
      "source": [
        "# %% of correct predictions : 54%\n",
        "new_df[filter].is_correct_prediction.value_counts() / len(new_df[filter])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVBAcObrGZzl"
      },
      "outputs": [],
      "source": [
        "# delete this column\n",
        "del new_df[\"is_correct_prediction\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hh7Gd_H_AU3"
      },
      "outputs": [],
      "source": [
        "# generate columns is_correct_\n",
        "for pred in PREDICTIONS:\n",
        "  part1 = pred.split('_')[0] # first prefix before '_'\n",
        "  new_df[f'is_correct_{part1}'] =  (new_df[pred] == new_df.is_positive_growth_5d_future).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elm6SLsVCX8L"
      },
      "outputs": [],
      "source": [
        "# IS_CORRECT dataset\n",
        "IS_CORRECT =  [k for k in new_df.keys() if k.startswith('is_correct_')]\n",
        "IS_CORRECT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhxTefjEC0Mi"
      },
      "outputs": [],
      "source": [
        "new_df[PREDICTIONS+IS_CORRECT+['is_positive_growth_5d_future']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeKyzptN_hoA"
      },
      "outputs": [],
      "source": [
        "len(new_df[new_df.split=='test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b8gV4iXC9HV"
      },
      "outputs": [],
      "source": [
        "# define \"Precision\" for ALL predictions on a Test dataset (~4 last years of trading)\n",
        "for i,column in enumerate(IS_CORRECT):\n",
        "  prediction_column = PREDICTIONS[i]\n",
        "  is_correct_column = column\n",
        "  filter = (new_df.split=='test') & (new_df[prediction_column]==1)\n",
        "  print(f'Prediction column:{prediction_column} , is_correct_column: {is_correct_column}')\n",
        "  print(new_df[filter][is_correct_column].value_counts())\n",
        "  print(new_df[filter][is_correct_column].value_counts()/len(new_df[filter]))\n",
        "\n",
        "  print('---------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yq6jsaZ72x_"
      },
      "source": [
        "## 1.3) [Code Snippet 4 - Advanced] Statistical prediction : ARIMA models with 3 parameters (p,q,r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS9f4TdAbMK9"
      },
      "outputs": [],
      "source": [
        "!pip install pmdarima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXTVZXmTbU5I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pmdarima import auto_arima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGMAuKZMbWHx"
      },
      "outputs": [],
      "source": [
        "# Set 'Date' as the index\n",
        "df_arima = df_nvda.copy()\n",
        "\n",
        "df_arima.set_index('Date', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW1G97ynb9P9"
      },
      "outputs": [],
      "source": [
        "df_arima.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGRgl1lmfzVR"
      },
      "outputs": [],
      "source": [
        "# use ONLY time-series values and no other features\n",
        "train_validation = df_arima[df_arima.split.isin(['train','validation'])]['Adj Close_x']\n",
        "test = df_arima[df_arima.split.isin(['test'])]['Adj Close_x']\n",
        "\n",
        "# this is needed to make a decision about investing for 5 days\n",
        "test_is_positive_future_5d = df_arima[df_arima.split.isin(['test'])]['is_positive_growth_5d_future']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRkcRkpFblK0"
      },
      "outputs": [],
      "source": [
        "# ~ several minutes to run\n",
        "# https://miqbalrp.medium.com/exploring-autoarima-in-python-for-multiple-time-series-forecasting-2f3004ba5a49\n",
        "# https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html\n",
        "# Auto ARIMA model fitting: iterating across params\n",
        "best_arima_model = auto_arima(train_validation,\n",
        "                   seasonal=False,\n",
        "                   trace=True,\n",
        "                   start_p=0, start_q=0, # minimum p and q\n",
        "                   max_p=12, max_q=12,   # maximum p and q\n",
        "                   D=None,               # let model determine 'D'\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLEybgl6ptou"
      },
      "outputs": [],
      "source": [
        "# best model specification trained on train_validation\n",
        "# (p=6, q=2, r=2)\n",
        "best_arima_model.get_params()['order']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-0cDnIRtVAa"
      },
      "outputs": [],
      "source": [
        "# need to do 918 predictions for 1 stock\n",
        "len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJVvyBb2qZJ8"
      },
      "outputs": [],
      "source": [
        "# model parameters (\"coef\" for auto-regression (AR) and moving-average (MA))\n",
        "best_arima_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF2fXpEiprC6"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5shB4BXzmSd"
      },
      "outputs": [],
      "source": [
        "# this was used to train the model and obtain the \"best\" params\n",
        "train_validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f64nUOemzjsF"
      },
      "outputs": [],
      "source": [
        "# history as Series and the \"last value\" (current last known data)\n",
        "history = [x for x in train_validation]\n",
        "history[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPUrMBbwz2ws"
      },
      "outputs": [],
      "source": [
        "# now need to predict for each value of test, using all available history\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxaiFmr9D3f5"
      },
      "outputs": [],
      "source": [
        "# slow to predict, can't quickly predict for ALL 33 tickers * 918 observationa (~30k predictions). Let's have only 1 ticker and these periods to predict:\n",
        "# change this to 10 (1 min) or 50 (5min) to run faster\n",
        "\n",
        "PERIODS_TO_PREDICT = 10  # ~1 minute to predict\n",
        "# PERIODS_TO_PREDICT = 500  #VERY SLOW: used for slides"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_rMX2StlyYx"
      },
      "outputs": [],
      "source": [
        "# staring to predict at day1 of test dataframe (we SEE the adj_close price and predict 5 periods ahead)\n",
        "df_arima[df_arima.split=='test'].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bialu8XedRNK"
      },
      "outputs": [],
      "source": [
        "# rolling forecast for ARIMA(6,2,2) model\n",
        "# https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python/\n",
        "\n",
        "%%time\n",
        "\n",
        "# start from all previous history of train_validation\n",
        "history = [x for x in train_validation]\n",
        "predictions = []\n",
        "decisions = []\n",
        "is_correct_decisions = []\n",
        "\n",
        "tp=0 # true positive\n",
        "fp=0 # false positive\n",
        "\n",
        "# walk-forward validation for PERIODS_TO_PREDICT\n",
        "for t in range(PERIODS_TO_PREDICT):\n",
        "  current_adj_close = test[t] # current adj_close price when we do the prediction\n",
        "  current_is_future_growth_5d = test_is_positive_future_5d[t]\n",
        "\n",
        "  model = ARIMA(history, order = best_arima_model.get_params()['order']) # substitute best parameters AND RETRAIN the model (very expensive)\n",
        "  model_fit = model.fit()\n",
        "  output = model_fit.forecast(steps=5) # forecast for 5 periods ahead\n",
        "\n",
        "  yhat = output[4] # prediction 5 periods ahead\n",
        "\n",
        "  if output[4] > current_adj_close:\n",
        "    prediction = 1\n",
        "  else:\n",
        "    prediction = 0\n",
        "\n",
        "  is_correct = (prediction==current_is_future_growth_5d).astype(int)\n",
        "\n",
        "  if prediction == 1:\n",
        "    if is_correct ==1:\n",
        "      tp+=1\n",
        "    else:\n",
        "      fp+=1\n",
        "\n",
        "  predictions.append(yhat)\n",
        "\n",
        "  decisions.append(prediction)\n",
        "  is_correct_decisions.append(is_correct)\n",
        "  obs = test[t+6]\n",
        "  history.append(obs) # add last element to history\n",
        "  print(f'step {t}, current_price = {np.round(current_adj_close,1)}, [5 periods] predicted={np.round(output,1)}, expected={np.round(test[t+1:t+6].values,1)}, decision = {prediction}, is_correct = {is_correct} ')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zikx03sODYvx"
      },
      "outputs": [],
      "source": [
        "tp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM-nukgUDaoP"
      },
      "outputs": [],
      "source": [
        "fp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2T5jYhFxDb6r"
      },
      "outputs": [],
      "source": [
        "precision = tp / (tp+fp)\n",
        "precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uwsjs5lY5i62"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16,8))\n",
        "test\n",
        "plt.plot(train_validation.index[-100:], train_validation.tail(100), color='green', label = 'Train+Validation Stock Price')\n",
        "plt.plot(test.index[5:PERIODS_TO_PREDICT+5], test[5:PERIODS_TO_PREDICT+5], color = 'red', label = 'Real Stock Price')\n",
        "plt.plot(test.index[5:PERIODS_TO_PREDICT+5], predictions, color = 'blue', label = 'Predicted Stock Price (5 periods ahead)')\n",
        "plt.title('NVDA Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('NVDA Stock Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjHY1B-1Bvtf"
      },
      "source": [
        "## 1.4) [Code Snippet 5] Binary Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHrM1sdLdYc"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oYKW8lodlM7"
      },
      "source": [
        "### 1.4.1) Define dataframes AND perform data cleaning\n",
        "* define X_train (dataframe), X_test (dataframe), y_train (series), y_test (series)\n",
        "* replace +-inf. with 0\n",
        "* fill NaNs with 0 (you can drop it too, but will loose a lot of data in our case\n",
        "* remove 1-2% outliers (in each dimension, or only in variable to_predict :: we won't use it for a Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNjsv3RtNjCu"
      },
      "outputs": [],
      "source": [
        "# Decision Tree doesn't like too large and inf. values\n",
        "import numpy as np\n",
        "\n",
        "def remove_infinite_values(X):\n",
        "    \"\"\"\n",
        "    Remove infinite values from the input array.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Input array (NumPy array or array-like)\n",
        "\n",
        "    Returns:\n",
        "    - Array with infinite values removed\n",
        "    \"\"\"\n",
        "    return X[np.isfinite(X).all(axis=1)]\n",
        "\n",
        "# Example usage:\n",
        "# Assuming X is your input data\n",
        "# filtered_X = remove_infinite_values(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpXBvokZPLTM"
      },
      "outputs": [],
      "source": [
        "# look carefully for 'count' to be close to total values (or you need to replace NaNs/remove NaNs), and min/max doesn't equal to -+inf.\n",
        "#  it will give you an idea to dig deeper into some features to understand the 'nature' of a problem\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "new_df[NUMERICAL+DUMMIES].describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoiZYkfhQa_g"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets based on the split date\n",
        "features_list = NUMERICAL+DUMMIES\n",
        "to_predict = 'is_positive_growth_5d_future'\n",
        "\n",
        "train_df = new_df[new_df.split.isin(['train','validation'])].copy(deep=True)\n",
        "test_df = new_df[new_df.split.isin(['test'])].copy(deep=True)\n",
        "\n",
        "# ONLY numerical Separate features and target variable for training and testing sets\n",
        "# need Date and Ticker later when merging predictions to the dataset\n",
        "X_train = train_df[features_list+[to_predict,'Date','Ticker']]\n",
        "X_test = test_df[features_list+[to_predict,'Date','Ticker']]\n",
        "\n",
        "print(f'length: X_train {X_train.shape},  X_test {X_test.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46GYMy7KRUB3"
      },
      "outputs": [],
      "source": [
        "# Can't have +-inf values . E.g. ln(volume)=-inf when volume==0 => substitute with 0\n",
        "\n",
        "# Disable SettingWithCopyWarning\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Need to fill NaNs somehow\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)\n",
        "\n",
        "print(f'length: X_train_imputed {X_train.shape},  X_test_imputed {X_test.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiJKy6vPWB19"
      },
      "outputs": [],
      "source": [
        "# you may want to remove 1-2% outliers based on percentile ==> not used here in Decision Trees\n",
        "def remove_outliers_percentile(X, lower_percentile=1, upper_percentile=99):\n",
        "    \"\"\"\n",
        "    Remove outliers from the input array based on percentiles.\n",
        "\n",
        "    Parameters:\n",
        "    - X: Input array (NumPy array or array-like)\n",
        "    - lower_percentile: Lower percentile threshold (float, default=1)\n",
        "    - upper_percentile: Upper percentile threshold (float, default=99)\n",
        "\n",
        "    Returns:\n",
        "    - Array with outliers removed\n",
        "    \"\"\"\n",
        "    lower_bound = np.percentile(X, lower_percentile, axis=0)\n",
        "    upper_bound = np.percentile(X, upper_percentile, axis=0)\n",
        "    mask = np.logical_and(np.all(X >= lower_bound, axis=1), np.all(X <= upper_bound, axis=1))\n",
        "    return X[mask]\n",
        "\n",
        "# Example usage:\n",
        "# Assuming X is your input data\n",
        "# filtered_X = remove_outliers_percentile(X, lower_percentile=1, upper_percentile=99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-NNrhAKWXr8"
      },
      "outputs": [],
      "source": [
        "X_train_imputed = X_train # we won't use outliers removal to save more data to train: remove_outliers_percentile(X_train)\n",
        "X_test_imputed = X_test # we won't use outliers removal to save more data to test: remove_outliers_percentile(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBXvMVKWWgSc"
      },
      "outputs": [],
      "source": [
        "# same shape\n",
        "print(f'length: X_train_imputed {X_train_imputed.shape},  X_test_imputed {X_test_imputed.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6A_zhDLW0aC"
      },
      "outputs": [],
      "source": [
        "y_train = X_train_imputed[to_predict]\n",
        "y_test = X_test_imputed[to_predict]\n",
        "\n",
        "# remove y_train, y_test from X_ dataframes\n",
        "del X_train_imputed[to_predict]\n",
        "del X_test_imputed[to_predict]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUGSkY7yeO5F"
      },
      "source": [
        "### 1.4.2 Estimation of a Decision Tree model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsSxJEireSeW"
      },
      "outputs": [],
      "source": [
        "# INPUTS:\n",
        "# X_train_imputed : CLEAN dataFrame with only numerical features (train+validation periods)\n",
        "# X_test_imputed : CLEAN dataFrame with only numerical features (test periods)\n",
        "\n",
        "# y_train : true values for the train period\n",
        "# y_test  : true values for the test period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcJAw5w9R7pA"
      },
      "outputs": [],
      "source": [
        "# estimation/fit function (using dataframe of features X and what to predict y) --> optimising total accuracy\n",
        "# max_depth is hyperParameter\n",
        "def fit_decision_tree(X, y, max_depth=20):\n",
        "# Initialize the Decision Tree Classifier\n",
        "  clf = DecisionTreeClassifier(max_depth=max_depth)\n",
        "\n",
        "  # Fit the classifier to the training data\n",
        "  clf.fit(X, y)\n",
        "  return clf, X.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ES96NQpefU2z"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# drop 2 columns before fitting the tree, but we need those columns later for joins\n",
        "clf_20, train_columns = fit_decision_tree(X=X_train_imputed.drop(['Date','Ticker'],axis=1),\n",
        "                           y=y_train,\n",
        "                           max_depth=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClqSfId-gbMW"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "clf_10, train_columns = fit_decision_tree(X=X_train_imputed.drop(['Date','Ticker'],axis=1),\n",
        "                           y=y_train,\n",
        "                           max_depth=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x74N7Brb-IAm"
      },
      "outputs": [],
      "source": [
        "# TODO 3: TRAIN only on train dataset, experiment with trees with depth 1..20 --> find the best one on VALID dataset\n",
        "#       for the \"best\" tree model: find precision on the TEST set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QbUrS7Ygm2G"
      },
      "source": [
        "### 1.4.3 Inference for a Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csUq1CWISRCe"
      },
      "outputs": [],
      "source": [
        "def predict_decision_tree(clf:DecisionTreeClassifier, df_X:pd.DataFrame, y_true: pd.Series):\n",
        "  # Predict the target variable on the test data\n",
        "  y_pred = clf.predict(df_X)\n",
        "\n",
        "  max_depth = clf.tree_.max_depth\n",
        "  # Print the maximum depth\n",
        "  print(\"Maximum depth of the decision tree:\", max_depth)\n",
        "\n",
        "  # Calculate the accuracy/precision of the model\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  print(f'Accuracy ={accuracy}, precision = {precision}')\n",
        "\n",
        "  # resulting df\n",
        "  result_df = pd.concat([df_X, y_true, pd.Series(y_pred, index=df_X.index, name='pred_')], axis=1)\n",
        "\n",
        "  return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ72IOAaTE7N"
      },
      "outputs": [],
      "source": [
        "pred20 = predict_decision_tree(clf_20, X_test_imputed.drop(['Date','Ticker'],axis=1), y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpPj5Zxqhm5x"
      },
      "outputs": [],
      "source": [
        "# Predictions of a decision tree of depth \"20\"\n",
        "pred20.pred_.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37DPFof2h-Cy"
      },
      "outputs": [],
      "source": [
        "pred10 = predict_decision_tree(clf_10, X_test_imputed.drop(['Date','Ticker'],axis=1), y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFmjznLr8tbH"
      },
      "outputs": [],
      "source": [
        "pred10.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYuaQ7k-8eSu"
      },
      "outputs": [],
      "source": [
        "X_test_imputed.join(pred10['pred_']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x01xCtd9iLif"
      },
      "outputs": [],
      "source": [
        "# Predictions of a decision tree of depth \"10\" : many more \"positive\" predictions\n",
        "pred10.pred_.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pgIZ95bmLD3"
      },
      "outputs": [],
      "source": [
        "# define a new DF with the SAME index (used for joins)\n",
        "pred20_df = pred20[['pred_']].rename(columns={'pred_': 'pred_tree_clf20'})\n",
        "pred20_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iA7XdbPlyQ3"
      },
      "outputs": [],
      "source": [
        "# define a new DF with the SAME index (used for joins)\n",
        "pred10_df = pred10[['pred_']].rename(columns={'pred_': 'pred_tree_clf10'})\n",
        "pred10_df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U75FIcVJwlEg"
      },
      "source": [
        "### 1.4.4 Features Importance and Tree Visualisation of top levels (for clf10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSmvvHAHwsGA"
      },
      "outputs": [],
      "source": [
        "# visualisation: decision tree for a few levels (max_depth variable)\n",
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming clf is your trained DecisionTreeClassifier\n",
        "plt.figure(figsize=(20,10))  # Set the size of the figure\n",
        "plot_tree(clf_10,\n",
        "          filled=True,\n",
        "          feature_names=train_columns,\n",
        "          class_names=['Negative', 'Positive'],\n",
        "          max_depth=2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84F-Mk1P2sGb"
      },
      "outputs": [],
      "source": [
        "# Feautures importance function to predict future returns (based on the classifier)\n",
        "# get feature importance from 'clf' (classifier) and 'train_columns' (column names)\n",
        "\n",
        "def get_importances(clf, train_columns):\n",
        "  # Assuming clf is your trained DecisionTreeClassifier\n",
        "  feature_importance = clf.feature_importances_\n",
        "\n",
        "  # Assuming X_train is your training features\n",
        "  feature_names = train_columns\n",
        "\n",
        "  # Create a DataFrame to store feature importance\n",
        "  feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
        "\n",
        "  # Sort the DataFrame by importance in descending order\n",
        "  feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "  # Print or display the feature importance DataFrame\n",
        "  # print(feature_importance_df)\n",
        "  return feature_importance_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvOEn1v_2uHM"
      },
      "outputs": [],
      "source": [
        "get_importances(clf_10, train_columns).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abAwJp8R27gN"
      },
      "outputs": [],
      "source": [
        "get_importances(clf_20, train_columns).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM3yxUwxmYpI"
      },
      "source": [
        "### 1.4.5 Merge with the original df for predictions (only when predicted on test dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WgTBvWxidv0"
      },
      "outputs": [],
      "source": [
        "# current predictions from MANUAL\n",
        "PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-Ew-Mpxi7O3"
      },
      "outputs": [],
      "source": [
        "new_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjlrnD3h9htb"
      },
      "outputs": [],
      "source": [
        "# index in df is not unique\n",
        "np.sort(new_df.groupby(new_df.index).split.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSFV3LEC5a7y"
      },
      "outputs": [],
      "source": [
        "# it's hard to join with pred10_df - as index is totally different\n",
        "pred10_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3scA_5KnLbZ"
      },
      "outputs": [],
      "source": [
        "# TODO 4: JOIN predictions with the original dataframe (define a new column):\n",
        "#  so, that there are columns pred_tree_clf10 AND pred_tree_clf20"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}